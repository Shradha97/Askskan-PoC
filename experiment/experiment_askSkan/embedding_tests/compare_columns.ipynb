{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sqlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignore this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "excel_file = \"./select_cols.xlsx\"\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Initialize an empty list to store unmatched columns for each row\n",
    "all_unmatched_columns = []\n",
    "\n",
    "df_len = len(df)\n",
    "# Iterate through the first 10 rows (adjust the range if needed)\n",
    "for i in range(df_len):\n",
    "    # Extract SQL statements from the correct_query and temp_0 columns\n",
    "    sql1 = df['temp_0'].iloc[i]\n",
    "    sql2 = df['correct_query'].iloc[i]\n",
    "    \n",
    "    if sql1 == \"not_evaluated\":\n",
    "        print(f\"Row {i+1}:Not evaluated\")\n",
    "        continue\n",
    "    \n",
    "    # Extract column names using regex\n",
    "    pattern = r\"SELECT\\s+(.*?)\\s+FROM\"\n",
    "    columns_sql1 = re.search(pattern, sql1, re.IGNORECASE).group(1)\n",
    "    columns_sql2 = re.search(pattern, sql2, re.IGNORECASE).group(1)\n",
    "    \n",
    "    # Create sets of column names\n",
    "    set_columns_sql1 = set(map(str.strip, columns_sql1.split(',')))\n",
    "    set_columns_sql2 = set(map(str.strip, columns_sql2.split(',')))\n",
    "    \n",
    "    # Find unmatched columns for this row\n",
    "    unmatched_columns = set_columns_sql1 - set_columns_sql2\n",
    "    \n",
    "    # Append unmatched columns to the list\n",
    "    all_unmatched_columns.append(unmatched_columns)\n",
    "\n",
    "# Print unmatched columns for each row\n",
    "for i, unmatched_columns in enumerate(all_unmatched_columns):\n",
    "    print(f\"Unmatched Columns for Row {i + 1}:\", unmatched_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_columns(sql_query, column_list):\n",
    "\n",
    "    # Extract column names from the SELECT statement using regex\n",
    "    pattern = r'SELECT\\s+(.+?)\\s+FROM'\n",
    "    match = re.search(pattern, sql_query, re.IGNORECASE)\n",
    "    \n",
    "    print(\"SQL query:\", sql_query)\n",
    "    selected_columns = match.group(1).split(',')\n",
    "\n",
    "    # Process each selected column\n",
    "    valid_columns = []\n",
    "    for col in selected_columns:\n",
    "        # Handle functions and aliases using regex\n",
    "        col = re.sub(r'\\s+AS\\s+\\w+', '', col, flags=re.IGNORECASE).strip()\n",
    "        col = re.sub(r'[^()\\s]*\\(', '', col).strip()  # Remove functions if present\n",
    "        col = col.strip('()')  # Remove parentheses if present\n",
    "        col = re.sub(r'^\\s*DISTINCT\\s+', '', col, flags=re.IGNORECASE)  # Remove DISTINCT if present\n",
    "        \n",
    "        \n",
    "        if col.strip() not in ['*', \"'EEEE'\", '12', '2', \"'%W'\"]:\n",
    "            valid_columns.append(col.strip())\n",
    "\n",
    "    print(\"SQL columns:\", valid_columns)\n",
    "\n",
    "    # Check if selected columns are in the list\n",
    "    missing_columns = [col for col in valid_columns if col not in column_list]\n",
    "    \n",
    "    if not missing_columns:\n",
    "        return valid_columns, None, 0\n",
    "    else:\n",
    "        return valid_columns, missing_columns, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "col_excel_file = \"./test_cols.xlsx\"\n",
    "col_df = pd.read_excel(col_excel_file)\n",
    "\n",
    "# Initialize an empty list to store unmatched columns for each row\n",
    "all_unmatched_columns = []\n",
    "generated_sql_queries = []\n",
    "selected_columns = []\n",
    "missing_columns = []\n",
    "is_missing_columns = []\n",
    "\n",
    "col_df_len = len(col_df)\n",
    "\n",
    "\n",
    "# Process each input string\n",
    "for i in range(col_df_len):\n",
    "    input_string = col_df['temp_col_0.6'].iloc[i]\n",
    "    sql2 = col_df['correct_query'].iloc[i]\n",
    "\n",
    "    if input_string == \"not_evaluated\" or sql2 == \"not_evaluated\":\n",
    "        # print(f\"Row {i+1}:Not evaluated\")\n",
    "        all_unmatched_columns.append(\"not_evaluated\")\n",
    "        generated_sql_queries.append(\"not_evaluated\")\n",
    "        selected_columns.append(\"not_evaluated\")\n",
    "        missing_columns.append(\"not_evaluated\")\n",
    "        is_missing_columns.append(0)\n",
    "    else:\n",
    "        print(f\"Row {i+1}\")\n",
    "        # Find the position of the SQL query\n",
    "        query_start = input_string.index(\"SELECT\")\n",
    "\n",
    "        # Extract the list part\n",
    "        list_part = input_string[:query_start].strip()\n",
    "\n",
    "        # Extract the SQL query part\n",
    "        sql_query_part = input_string[query_start:]\n",
    "\n",
    "        # Remove the surrounding square brackets and single quotes from the list\n",
    "        column_list = [column.strip(\"' \") for column in list_part.strip(\"[]\").split(',')]\n",
    "\n",
    "        generated_sql_queries.append(sql_query_part)\n",
    "\n",
    "        #Extract missing correct columns from the embedding list\n",
    "        valid_cols, missing_cols, is_missing = get_missing_columns(sql2, list_part)\n",
    "\n",
    "        # Extract column names using regex\n",
    "        pattern = r\"SELECT\\s+(.*?)\\s+FROM\"\n",
    "        columns_sql1 = re.search(pattern, sql_query_part, re.IGNORECASE).group(1)\n",
    "        columns_sql2 = re.search(pattern, sql2, re.IGNORECASE).group(1)\n",
    "        \n",
    "        # Create sets of column names\n",
    "        set_columns_sql1 = set(map(str.strip, columns_sql1.split(',')))\n",
    "        set_columns_sql2 = set(map(str.strip, columns_sql2.split(',')))\n",
    "        \n",
    "        # Find unmatched columns for this row\n",
    "        unmatched_columns = set_columns_sql1 - set_columns_sql2\n",
    "        \n",
    "        # Append unmatched columns to the list\n",
    "        all_unmatched_columns.append(unmatched_columns) if unmatched_columns else all_unmatched_columns.append(\"None\")\n",
    "        selected_columns.append(list_part)\n",
    "        missing_columns.append(missing_cols) if missing_cols else missing_columns.append(\"None\")\n",
    "        is_missing_columns.append(is_missing)\n",
    "\n",
    "# Add a new column \"Unmatched_Columns\" to the DataFrame\n",
    "# col_df[\"Unmatched_Columns\"] = all_unmatched_columns\n",
    "col_df[\"temp_0.6\"] = generated_sql_queries\n",
    "col_df[\"Embedding_cols\"] = selected_columns\n",
    "col_df[\"Missing_cols\"] = missing_columns\n",
    "col_df[\"is_missing\"] = is_missing_columns\n",
    "\n",
    "# Save the updated DataFrame to the same Excel file\n",
    "col_df.to_excel(col_excel_file, index=False, sheet_name=\"temp_0.6\")\n",
    "\n",
    "\n",
    "# Print unmatched columns for each row\n",
    "# for i, unmatched_columns in enumerate(all_unmatched_columns):\n",
    "#     print(f\"Unmatched Columns for Row {i + 1}:\", unmatched_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
