{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-05-15' # this may change in the future\n",
    "\n",
    "max_tokens = 1000\n",
    "chat_temperature = 0\n",
    "deployment_name=os.getenv(\"AZURE_OPENAI_DNAME\")#'skangpt35turbo0613' #This will correspond to the custom name you chose for your deployment when you deployed a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a completion call to generate an answer\n",
    "print('Sending a test completion job')\n",
    "start_phrase = 'Write a tagline for an ice cream shop. '\n",
    "# response = openai.Completion.create(engine=deployment_name, prompt=start_phrase, max_tokens=10)\n",
    "# print (response)\n",
    "# text = response['choices'][0]['text'].replace('\\n', '').replace(' .', '.').strip()\n",
    "# print(start_phrase+text)\n",
    "# response = openai.Completion.create(engine=deployment_name, prompt=start_phrase, max_tokens=10)\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=deployment_name, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you give me python code to reverse string \"},\n",
    "    ], max_tokens=100)\n",
    "print(response['choices'][0]['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LangChain with Azure OpenAI\n",
    "chat_llm = AzureChatOpenAI(\n",
    "    deployment_name=deployment_name,\n",
    "    openai_api_version=openai.api_version,\n",
    "    max_tokens=max_tokens,\n",
    "    temperature=chat_temperature,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can integrate this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory for chat history, use the completion model to summarize past conversations\n",
    "llm = AzureOpenAI(\n",
    "    model_name=COMPLETION_MODEL,\n",
    "    deployment_name=COMPLETION_DEPLOYMENT,\n",
    "    max_tokens=SUMMARY_MAX_TOKENS,\n",
    "    temperature=SUMMARY_TEMPERATURE,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2022-12-01' # this may change in the future\n",
    "\n",
    "deployment_name=os.getenv('AZURE_OPENAI_EMBED_NAME')\n",
    "\n",
    "url = openai.api_base + \"/openai/deployments?api-version=2022-12-01\" \n",
    "\n",
    "r = requests.get(url, headers={\"api-key\": openai.api_key})\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, numpy as np\n",
    "\n",
    "one = openai.Embedding.create(input = [\"Hello there\"], deployment_id=deployment_name)['data'][0]['embedding']\n",
    "two = openai.Embedding.create(input = [\"How are you\"], deployment_id=deployment_name)['data'][0]['embedding']\n",
    "three = openai.Embedding.create(input = [\"apple\"], deployment_id=deployment_name)['data'][0]['embedding']\n",
    "four = openai.Embedding.create(input = [\"mango\"], deployment_id=deployment_name)['data'][0]['embedding']\n",
    "\n",
    "# cosine_similarity(yellow, banana)\n",
    "print(np.dot(one, two))\n",
    "print(np.dot(one, three))\n",
    "print(np.dot(two, three))\n",
    "print(np.dot(three, four))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
