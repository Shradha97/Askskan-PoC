{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pinecone\n",
    "import os\n",
    "import openai\n",
    "# from IPython.display import display, HTML\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "import re\n",
    "regex = r'(`{3}python)([\\w]*)\\n([\\S\\s]+?)\\n(`{3})'\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data/sample/productivity_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def askSkan(question, csv):\n",
    "    prompt = f\"\"\"\n",
    "    I have a pandas csv table called {csv[\"name\"]} to {csv[\"purpose\"]}. \n",
    "\n",
    "    The columns values are as in the following array {csv[\"columns\"]}.\n",
    "    \n",
    "    The column fields have the following names and description {csv[\"fields\"]}.\n",
    "\n",
    "    I was asked the following question in quotes: \"{question}\"\n",
    "\n",
    "    Can you give me a working pandas python code that will give me the answer?\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    match = re.search(regex, response)\n",
    "    if match:\n",
    "        sub_string = match.group()\n",
    "        pcode = '\\n'.join(sub_string.split('\\n')[ 1: -1 ])\n",
    "\n",
    "    return pcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'id', 'purpose': 'unique id'}, {'name': 'id', 'purpose': 'unique id'}]\n",
      "import pandas as pd\n",
      "\n",
      "# Load the CSV file into a pandas dataframe\n",
      "df = pd.read_csv('sample_qna_data.csv')\n",
      "\n",
      "# Group the data by participant_id and calculate the total processing time for each participant\n",
      "grouped = df.groupby('participant_id')['processing_time'].sum()\n",
      "\n",
      "# Sort the participants by their total processing time in descending order\n",
      "sorted_participants = grouped.sort_values(ascending=False)\n",
      "\n",
      "# Print the sorted list of participants\n",
      "print(sorted_participants)\n",
      "participant_id\n",
      "Mary     6006007007006206207207206106107307306406407407...\n",
      "Susan                          420430440450460470480490500\n",
      "John     300320310330340350360370380390 excel excel exc...\n",
      "Steve    1802001902101852202002302102402202502302602402...\n",
      "Name: processing_time, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "csv = {\n",
    "    \"name\": \"sample_qna_data.csv\",\n",
    "    \"purpose\": \"Log of various tasks performed by participants on different cases\",\n",
    "    # \"amit\": [\n",
    "    #     {\"name\": \"id\", \"purpose\": \"unique id\"},\n",
    "    #     {\"name\": \"id\", \"purpose\": \"unique id\"}\n",
    "    # ],\n",
    "    \"fields\": \"\\\n",
    "        'case_id' has the unique case number.\\\n",
    "        'case_status' has the current status of the case.\\\n",
    "        'case_type' has the type of the case being handled.\\\n",
    "        'task_name' is the sub process of the the process being followed.\\\n",
    "        'participant_id' has the name of the particpant performing the task.\\\n",
    "        'process_name' has the name of the proces being followed.\\\n",
    "        'process_variant' signifies which variant of the given process was being folowed.\\\n",
    "        'applications_used' is and arrary of the application names used for performing the process.\\\n",
    "        'processing_time' is the time taking in seconds on how long the task took.\\\n",
    "        'wait_time' has the time the participant waited before performing next task.\\\n",
    "        'turnaround_time' is the total time it took to turnaround the task.\\\n",
    "        'start_time' has the start time in YYYY-MM-DDTHH:MM:SSZ format.\\\n",
    "        'no_of_keystokes' has the number of keystrokes it took to perform the task.\\\n",
    "        'no_of_shortcut_keys' has the number of times shortcut keys were used to perform this task. \"\n",
    "}\n",
    "data = pd.read_csv(csv[\"name\"])\n",
    "\n",
    "csv[\"columns\"] = data.columns.values\n",
    "print(csv[\"amit\"])\n",
    "# question = \"Who uses the least number of keystrokes on average?\"\n",
    "question = \"Sort the managers based on productivity?\"\n",
    "\n",
    "response = askSkan(question, csv)\n",
    "print(response)\n",
    "exec(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab cells for experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "    prompt = f\"\"\"\n",
    "    I have a pandas csv table called \"productivity_data.csv\" to record the productivity of an Operator. The columns values are as in the following array: {data.columns.values}.\n",
    "\n",
    "    The Operator is more productive if they complete higher number of claims. The columns Vehicle, Theft, Flood and Fire \\\n",
    "        have the number of claims that Operatore has completed. Each Operator, works under a Manager which is recorded in the Manager field.\\\n",
    "        Each row also contains the Week number the claims were completed.\n",
    "\n",
    "        I was asked the followng question in quotes: \"{question}\"\n",
    "\n",
    "    Can you give me a pandas python code that will give me the answer?\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    match = re.search(regex, response)\n",
    "    if match:\n",
    "        sub_string = match.group()\n",
    "        pcode = '\\n'.join(sub_string.split('\\n')[ 1: -1 ])\n",
    "\n",
    "    # print(pcode)\n",
    "    return pcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample_qna_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Load the CSV file into a pandas dataframe\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39msample_qna_data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Group the dataframe by participant_id and sum the processing_time column\u001b[39;00m\n\u001b[1;32m      7\u001b[0m grouped \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mparticipant_id\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mprocessing_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32m~/Desktop/Repo/Prototypes/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/Repo/Prototypes/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/Repo/Prototypes/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/Repo/Prototypes/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/Repo/Prototypes/.venv/lib/python3.9/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_qna_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('sample_qna_data.csv')\n",
    "\n",
    "# Group the dataframe by participant_id and sum the processing_time column\n",
    "grouped = df.groupby('participant_id')['processing_time'].sum()\n",
    "\n",
    "# print (grouped)\n",
    "# Find the participant with the highest total processing time\n",
    "most_productive = grouped.idxmax()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The most productive participant is {most_productive}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert 1001051021101151201251301351402023-05-01T18:00:00Z2023-05-02T08:00:00Z2023-05-02T11:00:00Z2023-05-02T14:00:00Z2023-05-02T17:00:00Z2023-05-03T08:00:00Z2023-05-03T11:00:00Z2023-05-03T14:00:00Z2023-05-03T17:00:00Z2023-05-04T08:00:00Z2023-05-04T11:00:00Z2023-05-04T14:00:00Z2023-05-04T17:00:00Z2023-05-05T08:00:00Z2023-05-05T11:00:00Z2023-05-05T14:00:00Z2023-05-05T17:00:00Z2023-05-06T08:00:00Z2023-05-06T11:00:00Z2023-05-06T14:00:00Z2023-05-06T17:00:00Z2023-05-07T08:00:00Z2023-05-07T11:00:00Z2023-05-07T14:00:00Z2023-05-07T17:00:00Z2023-05-08T08:00:00Z2023-05-08T11:00:00Z to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1490\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49m_cython_operation(\n\u001b[1;32m   1491\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39maggregate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1492\u001b[0m         values,\n\u001b[1;32m   1493\u001b[0m         how,\n\u001b[1;32m   1494\u001b[0m         axis\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1495\u001b[0m         min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m   1496\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1497\u001b[0m     )\n\u001b[1;32m   1498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m ngroups \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngroups\n\u001b[0;32m--> 959\u001b[0m \u001b[39mreturn\u001b[39;00m cy_op\u001b[39m.\u001b[39;49mcython_operation(\n\u001b[1;32m    960\u001b[0m     values\u001b[39m=\u001b[39;49mvalues,\n\u001b[1;32m    961\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    962\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m    963\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    964\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[1;32m    965\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    966\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[1;32m    650\u001b[0m         values,\n\u001b[1;32m    651\u001b[0m         min_count\u001b[39m=\u001b[39mmin_count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    655\u001b[0m     )\n\u001b[0;32m--> 657\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_op_ndim_compat(\n\u001b[1;32m    658\u001b[0m     values,\n\u001b[1;32m    659\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m    660\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[1;32m    661\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mcomp_ids,\n\u001b[1;32m    662\u001b[0m     mask\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    663\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    664\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:482\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m     result_mask \u001b[39m=\u001b[39m result_mask[\u001b[39mNone\u001b[39;00m, :]\n\u001b[0;32m--> 482\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_cython_op(\n\u001b[1;32m    483\u001b[0m     values2d,\n\u001b[1;32m    484\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m    485\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[1;32m    486\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mcomp_ids,\n\u001b[1;32m    487\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    488\u001b[0m     result_mask\u001b[39m=\u001b[39;49mresult_mask,\n\u001b[1;32m    489\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    490\u001b[0m )\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m res\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m out_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[0;32m--> 541\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cython_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkind, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow, values\u001b[39m.\u001b[39;49mdtype, is_numeric)\n\u001b[1;32m    542\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[0;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39m__signatures__:\n\u001b[1;32m    172\u001b[0m     \u001b[39m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfunction is not implemented for this dtype: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[how->\u001b[39m\u001b[39m{\u001b[39;00mhow\u001b[39m}\u001b[39;00m\u001b[39m,dtype->\u001b[39m\u001b[39m{\u001b[39;00mdtype_str\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1692\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(x)\n\u001b[1;32m   1693\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1694\u001b[0m     \u001b[39m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1001051021101151201251301351402023-05-01T18:00:00Z2023-05-02T08:00:00Z2023-05-02T11:00:00Z2023-05-02T14:00:00Z2023-05-02T17:00:00Z2023-05-03T08:00:00Z2023-05-03T11:00:00Z2023-05-03T14:00:00Z2023-05-03T17:00:00Z2023-05-04T08:00:00Z2023-05-04T11:00:00Z2023-05-04T14:00:00Z2023-05-04T17:00:00Z2023-05-05T08:00:00Z2023-05-05T11:00:00Z2023-05-05T14:00:00Z2023-05-05T17:00:00Z2023-05-06T08:00:00Z2023-05-06T11:00:00Z2023-05-06T14:00:00Z2023-05-06T17:00:00Z2023-05-07T08:00:00Z2023-05-07T11:00:00Z2023-05-07T14:00:00Z2023-05-07T17:00:00Z2023-05-08T08:00:00Z2023-05-08T11:00:00Z'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1696\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39;49m(x)\n\u001b[1;32m   1697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1698\u001b[0m     \u001b[39m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39msample_qna_data.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# group the dataframe by participant_id and calculate the mean of no_of_keystrokes for each group\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m avg_keystrokes \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mparticipant_id\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39;49m\u001b[39mno_of_keystrokes\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmean()\n\u001b[1;32m      9\u001b[0m \u001b[39m# find the participant with the lowest average keystrokes\u001b[39;00m\n\u001b[1;32m     10\u001b[0m min_keystrokes \u001b[39m=\u001b[39m avg_keystrokes\u001b[39m.\u001b[39midxmin()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   1854\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1855\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_agg_general(\n\u001b[1;32m   1856\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1857\u001b[0m         alt\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[1;32m   1858\u001b[0m         numeric_only\u001b[39m=\u001b[39;49mnumeric_only,\n\u001b[1;32m   1859\u001b[0m     )\n\u001b[1;32m   1860\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_py_fallback(values, ndim\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mndim, alt\u001b[39m=\u001b[39malt)\n\u001b[1;32m   1505\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 1507\u001b[0m new_mgr \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mgrouped_reduce(array_func)\n\u001b[1;32m   1508\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   1509\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/base.py:193\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrouped_reduce\u001b[39m(\u001b[39mself\u001b[39m, func):\n\u001b[1;32m    192\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marray\n\u001b[0;32m--> 193\u001b[0m     res \u001b[39m=\u001b[39m func(arr)\n\u001b[1;32m    194\u001b[0m     index \u001b[39m=\u001b[39m default_index(\u001b[39mlen\u001b[39m(res))\n\u001b[1;32m    196\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1490\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39m_cython_operation(\n\u001b[1;32m   1491\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1492\u001b[0m         values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1497\u001b[0m     )\n\u001b[1;32m   1498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[0;32m-> 1503\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_agg_py_fallback(values, ndim\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim, alt\u001b[39m=\u001b[39;49malt)\n\u001b[1;32m   1505\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     ser \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m   1454\u001b[0m \u001b[39m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m \u001b[39m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \u001b[39m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[0;32m-> 1457\u001b[0m res_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(ser, alt, preserve_dtype\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, Categorical):\n\u001b[1;32m   1460\u001b[0m     \u001b[39m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m     \u001b[39m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m     \u001b[39m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m     res_values \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(values)\u001b[39m.\u001b[39m_from_sequence(res_values, dtype\u001b[39m=\u001b[39mvalues\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39m_values, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    988\u001b[0m     \u001b[39m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[39m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[39m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[39m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    996\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    997\u001b[0m \u001b[39mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1012\u001b[0m splitter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_splitter(obj, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   1014\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[0;32m-> 1015\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[1;32m   1016\u001b[0m     res \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(res)\n\u001b[1;32m   1018\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initialized:\n\u001b[1;32m   1019\u001b[0m         \u001b[39m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   1854\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1855\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   1856\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m-> 1857\u001b[0m         alt\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[1;32m   1858\u001b[0m         numeric_only\u001b[39m=\u001b[39mnumeric_only,\n\u001b[1;32m   1859\u001b[0m     )\n\u001b[1;32m   1860\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11539\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  11540\u001b[0m     _num_doc,\n\u001b[1;32m  11541\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the mean of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11554\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11555\u001b[0m ):\n\u001b[0;32m> 11556\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mmean(\u001b[39mself\u001b[39;49m, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m  11195\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11196\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11199\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11200\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 11201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[1;32m  11202\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11203\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11154\u001b[0m     nv\u001b[39m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[39m=\u001b[39mname)\n\u001b[1;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m> 11158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11159\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[1;32m  11160\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:4666\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4661\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   4662\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not allow \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mnumeric_only\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4663\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith non-numeric dtypes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4664\u001b[0m     )\n\u001b[1;32m   4665\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 4666\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    156\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[0;32m--> 421\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, mask\u001b[39m=\u001b[39;49mmask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[1;32m    424\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    724\u001b[0m     dtype_count \u001b[39m=\u001b[39m dtype\n\u001b[1;32m    726\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[0;32m--> 727\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum))\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    730\u001b[0m     count \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1696\u001b[0m             x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39m(x)\n\u001b[1;32m   1697\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1698\u001b[0m             \u001b[39m# e.g. \"foo\"\u001b[39;00m\n\u001b[0;32m-> 1699\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m to numeric\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert 1001051021101151201251301351402023-05-01T18:00:00Z2023-05-02T08:00:00Z2023-05-02T11:00:00Z2023-05-02T14:00:00Z2023-05-02T17:00:00Z2023-05-03T08:00:00Z2023-05-03T11:00:00Z2023-05-03T14:00:00Z2023-05-03T17:00:00Z2023-05-04T08:00:00Z2023-05-04T11:00:00Z2023-05-04T14:00:00Z2023-05-04T17:00:00Z2023-05-05T08:00:00Z2023-05-05T11:00:00Z2023-05-05T14:00:00Z2023-05-05T17:00:00Z2023-05-06T08:00:00Z2023-05-06T11:00:00Z2023-05-06T14:00:00Z2023-05-06T17:00:00Z2023-05-07T08:00:00Z2023-05-07T11:00:00Z2023-05-07T14:00:00Z2023-05-07T17:00:00Z2023-05-08T08:00:00Z2023-05-08T11:00:00Z to numeric"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the csv file into a pandas dataframe\n",
    "df = pd.read_csv('sample_qna_data.csv')\n",
    "\n",
    "# group the dataframe by participant_id and calculate the mean of no_of_keystrokes for each group\n",
    "avg_keystrokes = df.groupby('participant_id')['no_of_keystrokes'].mean()\n",
    "\n",
    "# find the participant with the lowest average keystrokes\n",
    "min_keystrokes = avg_keystrokes.idxmin()\n",
    "\n",
    "print(\"The participant who uses the least number of keystrokes on average is:\", min_keystrokes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
