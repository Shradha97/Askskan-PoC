# Answer Skan Tool

This tool is created to Test/Evaluate  Askskan model.     

###Automate Test run
For getting responses (ex-SQL query, SQL result etc ) from AskSkan model   

```
1. activate .venv (AskSkan virtual environment where requirement.txt is installed)
2. export PYTHONPATH=`pwd`
3. export PATH=.:$PATH
4. run through cli
```
|Argument           |  info    |  Required                                                                                                                                                                                                                                                            |
| ---------------------------------------------- | --------------- | ----------------------- | 
 |`-i`            | `file path of the csv that contain Questions`               | yes
 | `-o`            | `file path of the csv in which extracted query will be stored`               | optional (default = path of input csv)
   `-f`            | `starting index of Question`               | default = 1
  `-l`            | `ending index of Question`               | default = 10000
   `-path`            | `directory path of AskSkan module`               | yes
  `-run`            | `command for extracting query ,result etc`               | `example - askskan_-sql_-q ` represent `askskan -sql -q`
  `-col`            | `Column name of Result column in Output csv`               | default = test_1
  

                                                                                                   
###Compare Query 
For comparing Query ( generated by LLM model ) is equivalent to Correct Query or not.
```
1. run through cli
```
Argument        |  info    |  Required                                                                                                                                                                                                                                                                               |
| ---------------------------------------------- | --------------- | ----------------------- | 
 `-i`            | `file path of the csv that contain both set of  SQL queries`               | yes
  `-o`            | `file path of the csv in which the result will be stored`               |  default = path of input csv
   `-f`            | `starting index of query`               | default = 1
  `-l`            | `ending index of query`               | default = 11000
   `-c1`            | `column name of correct_queries`               | yes
  `-c2`            | `column name of queries that you want to test`               | yes
  
  
###Sql Skeleton
For a given set of query or question,  what are the different structure or skeleton present

```
1. Download spcay model "en_core_web_lg". run "python -m spacy download en_core_web_lg" and  "python -m spacy download en_core_web_sm" in the Terminal.
2. run through gradioo.py through cli by providing 2 paths -res response.csv path , -cen centroid.csv path  
3. Response csv contains the responses (query,question), centroid csv store the centroid that are formed from clusters.
4. make sure that response csv and centroid csv are not initialized (no question/query is clustered (assigned cluster id) in the response csv) before running gradioo.py
5. components of gradio interface 

```
Component        |  Function                                                                                                                                                                                                                                                                                   |
| ---------------------------------------------- | --------------- | 
 `Update button`            | `for updating the response csv with question and query and evaluate whether it belongs to current structures or new structure`    
  `ReInitialize Dropdown`            | `for re initializing the response and centroid csv`    
  `Initialized Maximum Node Depth` | `how pure you want the structures to be formed` default = auto                           
   `clear added responses ` | `clear all the new added responses in response csv`  

###Answers from python 
Getting Answers to Questions Implemented in Pyhton. 
```
1. run main.py through cli
```

Argument        |  info    |  Required                                                                                                                                                                                                                                                                               |
| ---------------------------------------------- | --------------- | ----------------------- 
 `-i`            | `file path of the csv that contain Question set`               | yes
  `-o`            | `file path of the csv in which the result will be stored`               |  default = path of input csv
   `-f`            | `starting index of Question to be evaluated`               | default = 1
  `-l`            | `ending index of Question to evaluated`               | default = 1107
   `-c`            | `column name of results`               | default = answer_column_name
  `-d`            | `file path of dataset csv`               | yes
###Evaluating LLM model
This tool is for evaluating AskSkan Model.
```
1.This Tool can be used to judge how well LLM model is performing by checking how many questions are correctly answered by model.​
2.Use question from evaluating_question_set.csv to evaluate the model.
3.run evaluating_llm_model.py for evaluating model. 
4. Run generate_evaluation_question_set.py ,to generate some more question from Chatgpt (need to check each generated  question answer correctness manually)​
```

Argument        |  info    |  Required                                                                                                                                                                                                                                                                               |
| ---------------------------------------------- | --------------- | ----------------------- 
 `-i`            | `file path of evaluation question set`               | yes
  `-path`            | `directory path where AskSkan module is present`               |  yes
 
  
  








  
  









